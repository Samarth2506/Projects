{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenerateFakes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aID55F8hvntd",
        "colab_type": "text"
      },
      "source": [
        "# Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJvvjYRoI8Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import modules\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as utils\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "torch.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cboz1Sb4vii_",
        "colab_type": "text"
      },
      "source": [
        "# Load and process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1-2DpsVIJtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=np.load(\"/content/drive/My Drive/CelebA/image_fake_array_10000.npy\")\n",
        "\n",
        "\n",
        "if data.shape[1:3]==(64, 64, 3):\n",
        "  data_array = np.transpose(data, (0, 1, 3, 2))\n",
        "  data_array = np.transpose(data_array, (0, 2, 1, 3))\n",
        "else:\n",
        "  data_array=data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JeWjp9QH7NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        self.data = data\n",
        "        self.targets = torch.LongTensor(targets)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.targets[index]\n",
        "\n",
        "        if self.transform:\n",
        "            x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1,2,0))\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "#Normalisation of Image\n",
        "transform_norm = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25))])\n",
        "\n",
        "dataset = MyDataset(data_array, np.zeros((array_val.shape[0],)), transform=transform_norm)\n",
        "dataloader = DataLoader(dataset, 1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU5_cPPFvacC",
        "colab_type": "text"
      },
      "source": [
        "#GAN code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ0svonjHxym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "\n",
        "class GeneratorResNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_residual_blocks):\n",
        "        super(GeneratorResNet, self).__init__()\n",
        "\n",
        "        global in_features\n",
        "        global out_features\n",
        "        channels = input_shape[0]\n",
        "        out_features = 64\n",
        "        # Initial convolution block\n",
        "\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(channels),\n",
        "            nn.Conv2d(channels, out_features, 7),\n",
        "            nn.InstanceNorm2d(out_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        in_features = out_features\n",
        "\n",
        "        # Downsampling\n",
        "        for _ in range(2):\n",
        "            out_features *= 2\n",
        "            model += [\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(num_residual_blocks):\n",
        "            model += [ResidualBlock(out_features)]\n",
        "        \n",
        "        self.model = nn.Sequential(*model)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class DecoderResNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_residual_blocks):\n",
        "        super(DecoderResNet, self).__init__()\n",
        "\n",
        "        global in_features\n",
        "        global out_features\n",
        "        channels = input_shape[0]\n",
        "        model=[]\n",
        "        # Upsampling\n",
        "        for _ in range(2):\n",
        "            out_features //= 2\n",
        "            model += [\n",
        "                nn.Upsample(scale_factor=2),\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # Output layer\n",
        "        model += [nn.ReflectionPad2d(channels), nn.Conv2d(out_features, channels, 7), nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "##############################\n",
        "#        Discriminator\n",
        "##############################\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        channels, height, width = input_shape\n",
        "\n",
        "        # Calculate output shape of image discriminator (PatchGAN)\n",
        "        self.output_shape = (1, height // 2 ** 4, width // 2 ** 4)\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
        "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(channels, 64, normalize=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8jkO2xnvQvQ",
        "colab_type": "text"
      },
      "source": [
        "# Load Generator state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nn7KHN7JcUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = GeneratorResNet(input_shape, 4)\n",
        "model2 = DecoderResNet(input_shape, 4)\n",
        "\n",
        "checkpoint = torch.load(\"/content/drive/My Drive/DL_GAN_train_master_4LAYER\")\n",
        "model1.load_state_dict(checkpoint['model_state_dict'][0])\n",
        "model2.load_state_dict(checkpoint['model_state_dict'][1])\n",
        "\n",
        "model1.cuda()\n",
        "model2.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU5U4giRuznb",
        "colab_type": "text"
      },
      "source": [
        "# Save numpy array of the GAN generated images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf8lcc0aJik8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_array=np.zeros((10000, 3, 64, 64))\n",
        "for i, (imgs, _) in enumerate(dataloader):\n",
        "  \n",
        "  model1.eval()\n",
        "  model2.eval()\n",
        "\n",
        "  real_A = Variable(imgs.type(Tensor))\n",
        "\n",
        "  fake_A = model2(model1(real_A))\n",
        "  image_array[i,:,:,:]=fake_A[0].detach().cpu().numpy()\n",
        "  if(i%1000==0):\n",
        "    print(i)\n",
        "\n",
        "np.save(\"/content/drive/My Drive/image_fake_array_10000_fakes_dense\", image_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVhPxDZvvATR",
        "colab_type": "text"
      },
      "source": [
        "# Save .jpg of the GAN generated Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcRTmi9kJ2ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (imgs, _) in enumerate(dataloader):\n",
        "  \n",
        "  model1.eval()\n",
        "  model2.eval()\n",
        "\n",
        "  real_A = Variable(imgs.type(Tensor))\n",
        "\n",
        "  fake_A = model2(model1(real_A))\n",
        "\n",
        "  utils.save_image(fake_A, \"/content/drive/My Drive/Imgs_10k_2,2star/images%s.png\" % i, normalize=False)\n",
        "  utils.save_image(real_A, \"/content/drive/My Drive/Imgs_10k_2,2star_real/images%s.png\" % i, normalize=False)\n",
        "\n",
        "  if(i%1000==0):\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}